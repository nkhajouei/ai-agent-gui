{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =======================================================================\n",
        "# STEP 1: INSTALL ALL REQUIRED STABLE LIBRARY VERSIONS\n",
        "# =======================================================================\n",
        "# This final version includes 'langchainhub', which is required for hub.pull().\n",
        "!pip install -q -U langchain==\"0.1.20\" langchain-core==\"0.1.52\" langchain-google-genai==\"1.0.4\" langsmith==\"0.1.57\" langchainhub==\"0.1.20\"\n",
        "\n",
        "# =======================================================================\n",
        "# STEP 2: CONFIGURE ENVIRONMENT\n",
        "# =======================================================================\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the official environment variable to disable LangSmith tracing.\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "\n",
        "# Configure your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "\n",
        "# =======================================================================\n",
        "# STEP 3: IMPORT LIBRARIES (WITH THE CORRECTED TYPO)\n",
        "# =======================================================================\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI  # <--- THIS IS THE FIX\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain import hub\n",
        "\n",
        "print(\"✅ All systems go! Setup is finally complete. You can now proceed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WDfFC5ddIGNa",
        "outputId": "a54be1ba-9afb-4b9b-c32b-4f2ca790c5c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All systems go! Setup is finally complete. You can now proceed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bulid the \"Math and Joke Agent\"\n",
        "# Here we define the logic and tools for the agent\n",
        "# Tool is a function that agent can use to perform a specific task\n",
        "\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtracts two numbers.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "@tool\n",
        "def tell_a_joke() -> str:\n",
        "    \"\"\"Tells a random joke.\"\"\"\n",
        "    jokes = [\n",
        "        \"Why don't scientists trust atoms? Because they make up everything!\",\n",
        "        \"What do you call fake spaghetti? An Impasta!\",\n",
        "        \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
        "    ]\n",
        "    import random\n",
        "    return random.choice(jokes)\n",
        "\n",
        "tools = [add, subtract, tell_a_joke]"
      ],
      "metadata": {
        "id": "uXPeoi80mvL7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intialize the Gemma LLM. Set up the connection to the Gemma model using \"langchain-google-genai\"\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\") # You can also use \"gemini-pro\"\n",
        "\n",
        "#from langchain_community.llms import Ollama\n",
        "#llm = Ollama(model=\"gemma:2b\")"
      ],
      "metadata": {
        "id": "oxAG4wjYpTFs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The final, complete, and correct version of Step 5\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain import hub\n",
        "\n",
        "# This JSON-aware prompt is correct.\n",
        "prompt = hub.pull(\"hwchase17/react-json\")\n",
        "\n",
        "# The agent creation is correct.\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# THE FIX IS HERE: We add the error handling flag to the AgentExecutor.\n",
        "# This makes the agent robust and allows it to self-correct.\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=False,\n",
        "    handle_parsing_errors=True  # <-- THE FINAL FIX\n",
        ")\n",
        "\n",
        "print(\"✅ Agent created with JSON prompt and self-correcting error handling.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhQvYkCvp-x6",
        "outputId": "fc828f52-8902-4836-dd5f-4fae73728000"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent created with JSON prompt and self-correcting error handling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_executor.invoke({\"input\": \"What is 12 plus 7?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mNuaDZn9NcE9",
        "outputId": "cde37c20-3829-4ee8-8d0a-5f0ef1a77884"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is 12 plus 7?',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_executor.invoke({\"input\": \"Tell me a joke.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J9l1VQIpfk46",
        "outputId": "aec265cc-ce21-454e-d837-22896d3c780d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Tell me a joke.',\n",
              " 'output': 'I am unable to tell you a joke because the provided tools are not functional.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_executor.invoke({\"input\": \"What is 25 subtract 11? After you give me the answer, tell me a joke.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v54_-4FSf8Gu",
        "outputId": "02b5c6fa-ec62-4f1c-9796-154241588f40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is 25 subtract 11? After you give me the answer, tell me a joke.',\n",
              " 'output': \"25 subtract 11 is 14.  Why don't scientists trust atoms? Because they make up everything!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradio library to create a simple web-based GUI\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "KGMhNQLrg1YQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# All of our agent logic is now inside this single function\n",
        "def run_agent(user_input):\n",
        "    import os\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain_core.tools import tool\n",
        "    from langchain.agents import AgentExecutor, create_react_agent\n",
        "    from langchain import hub\n",
        "\n",
        "    # 1. Define Tools\n",
        "    @tool\n",
        "    def add(a: int, b: int) -> int:\n",
        "        \"\"\"Adds two numbers.\"\"\"\n",
        "        return a + b\n",
        "\n",
        "    @tool\n",
        "    def subtract(a: int, b: int) -> int:\n",
        "        \"\"\"Subtracts two numbers.\"\"\"\n",
        "        return a - b\n",
        "\n",
        "    @tool\n",
        "    def tell_a_joke() -> str:\n",
        "        \"\"\"Tells a random joke.\"\"\"\n",
        "        jokes = [\n",
        "            \"Why don't scientists trust atoms? Because they make up everything!\",\n",
        "            \"What do you call fake spaghetti? An Impasta!\",\n",
        "            \"Why did the scarecrow win an award? Because he was outstanding in his field!\"\n",
        "        ]\n",
        "        import random\n",
        "        return random.choice(jokes)\n",
        "\n",
        "    tools = [add, subtract, tell_a_joke]\n",
        "\n",
        "    # 2. Initialize LLM (assuming API key is already set)\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "    # 3. Create Agent and Executor\n",
        "    prompt = hub.pull(\"hwchase17/react-json\")\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "    agent_executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=False, # We keep verbose off for a clean user experience\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "\n",
        "    # 4. Invoke the agent and get the response\n",
        "    response = agent_executor.invoke({\"input\": user_input})\n",
        "\n",
        "    # 5. Return only the final output string\n",
        "    return response['output']\n",
        "\n",
        "print(\"✅ Agent function is defined and ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rg3YgIMhApw",
        "outputId": "eedede9b-5829-415c-a5c1-d243684908b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent function is defined and ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the Gradio Interface\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Create the user interface\n",
        "iface = gr.Interface(\n",
        "    fn=run_agent,  # The function to call\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask your agent anything...\"), # A text box for input\n",
        "    outputs=\"text\", # The output is simple text\n",
        "    title=\"Math and Joke AI Agent\",\n",
        "    description=\"This agent can perform addition and subtraction, or tell you a joke. Based on Google's Gemini model.\"\n",
        ")\n",
        "\n",
        "# Launch the interface!\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "3yfYiVRTkvJE",
        "outputId": "99436d8d-b960-40bf-96a3-6a49507e04bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c17b145b569f24d394.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c17b145b569f24d394.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a requirements.txt file needed for github\n",
        "%%writefile requirements.txt\n",
        "langchain==\"0.1.20\"\n",
        "langchain-core==\"0.1.52\"\n",
        "langchain-google-genai==\"1.0.4\"\n",
        "langsmith==\"0.1.57\"\n",
        "langchainhub==\"0.1.20\"\n",
        "gradio"
      ],
      "metadata": {
        "id": "vQxBnvyy3OEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a readme.md file for github\n",
        "%%writefile README.md\n",
        "# Math and Joke AI Agent\n",
        "\n",
        "This project is a simple AI agent built with Python, LangChain, and Google's Gemini model. The agent can perform basic arithmetic (addition and subtraction) and tell jokes.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **Tool Use:** The agent is equipped with tools for adding, subtracting, and telling jokes.\n",
        "- **Web UI:** A simple web interface is provided using Gradio to easily interact with the agent.\n",
        "\n",
        "## How to Run\n",
        "\n",
        "1.  **Open in Colab:** The easiest way to run this project is to open the `.ipynb` notebook in Google Colab.\n",
        "2.  **Set API Key:** Before running, you must set your Google AI Studio API key. In the Colab notebook, go to the \"Secrets\" tab (key icon on the left) and add a new secret named `GOOGLE_API_KEY` with your key as the value.\n",
        "3.  **Run All Cells:** Click `Runtime -> Run all` to install the dependencies and launch the Gradio web interface. A public link will be generated."
      ],
      "metadata": {
        "id": "H5sjpXjB3WN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}